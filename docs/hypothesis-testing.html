<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Unit 4 Hypothesis Testing | An Introduction to Statistics</title>
  <meta name="description" content="Unit 4 Hypothesis Testing | An Introduction to Statistics" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Unit 4 Hypothesis Testing | An Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="mndpln/intro-statistics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Unit 4 Hypothesis Testing | An Introduction to Statistics" />
  
  
  

<meta name="author" content="Mariefel Nicole Deypalan" />


<meta name="date" content="2021-05-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="the-normal-distribution-and-the-central-limit-theorem.html"/>
<link rel="next" href="z-tests-t-tests-and-confidence-intervals.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>



<link rel="stylesheet" href="lib/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="lib/css/style.css" type="text/css" />
<link rel="stylesheet" href="lib/css/lesson.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">An Introduction to Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-data.html"><a href="introduction-to-data.html"><i class="fa fa-check"></i><b>1</b> Introduction to Data</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#what-is-data"><i class="fa fa-check"></i><b>1.1</b> What is Data?</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#types-of-data"><i class="fa fa-check"></i><b>1.2</b> Types of Data</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-data.html"><a href="introduction-to-data.html#homework"><i class="fa fa-check"></i><b>1.3</b> Homework</a></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-data.html"><a href="introduction-to-data.html#measures-of-central-tendencymct-wiki"><i class="fa fa-check"></i><b>1.4</b> Measures of Central Tendency</a></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-data.html"><a href="introduction-to-data.html#measures-of-variability"><i class="fa fa-check"></i><b>1.5</b> Measures of Variability</a></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-data.html"><a href="introduction-to-data.html#examining-numerical-data"><i class="fa fa-check"></i><b>1.6</b> Examining Numerical Data</a><ul>
<li class="chapter" data-level="1.6.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#numerical-methods"><i class="fa fa-check"></i><b>1.6.1</b> Numerical Methods</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#graphical-methods"><i class="fa fa-check"></i><b>1.6.2</b> Graphical Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction-to-data.html"><a href="introduction-to-data.html#examining-categorical-data"><i class="fa fa-check"></i><b>1.7</b> Examining Categorical Data</a><ul>
<li class="chapter" data-level="1.7.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#tabular-methods"><i class="fa fa-check"></i><b>1.7.1</b> Tabular Methods</a></li>
<li class="chapter" data-level="1.7.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#graphical-methods-1"><i class="fa fa-check"></i><b>1.7.2</b> Graphical Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="introduction-to-data.html"><a href="introduction-to-data.html#aside-some-number-theory"><i class="fa fa-check"></i><b>1.8</b> Aside: Some Number Theory</a><ul>
<li class="chapter" data-level="1.8.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#the-factorial"><i class="fa fa-check"></i><b>1.8.1</b> The Factorial</a></li>
<li class="chapter" data-level="1.8.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#combinations"><i class="fa fa-check"></i><b>1.8.2</b> Combinations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html"><i class="fa fa-check"></i><b>2</b> Probability and Probability Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#defining-probability"><i class="fa fa-check"></i><b>2.1</b> Defining Probability</a></li>
<li class="chapter" data-level="2.2" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#homework-1"><i class="fa fa-check"></i><b>2.2</b> Homework 1</a></li>
<li class="chapter" data-level="2.3" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#independence"><i class="fa fa-check"></i><b>2.3</b> Independence</a></li>
<li class="chapter" data-level="2.4" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#random-variables"><i class="fa fa-check"></i><b>2.4</b> Random Variables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#discrete-and-continuous"><i class="fa fa-check"></i><b>2.4.1</b> Discrete and Continuous</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#homework-2"><i class="fa fa-check"></i><b>2.5</b> Homework 2</a></li>
<li class="chapter" data-level="2.6" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#pmfs-and-pdfs"><i class="fa fa-check"></i><b>2.6</b> PMFs and PDFs</a></li>
<li class="chapter" data-level="2.7" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#the-uniform-distribution"><i class="fa fa-check"></i><b>2.7</b> The Uniform Distribution</a></li>
<li class="chapter" data-level="2.8" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#the-binomial-distribution"><i class="fa fa-check"></i><b>2.8</b> The Binomial Distribution</a><ul>
<li class="chapter" data-level="2.8.1" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#bernoulli-trial"><i class="fa fa-check"></i><b>2.8.1</b> Bernoulli Trial</a></li>
<li class="chapter" data-level="2.8.2" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#pmf-of-a-binomial-distributionma151"><i class="fa fa-check"></i><b>2.8.2</b> PMF of a Binomial Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#homework-3"><i class="fa fa-check"></i><b>2.9</b> Homework 3</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html"><i class="fa fa-check"></i><b>3</b> The Normal Distribution and the Central Limit Theorem</a><ul>
<li class="chapter" data-level="3.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#population-vs.-sample"><i class="fa fa-check"></i><b>3.1</b> Population vs.Â Sample</a><ul>
<li class="chapter" data-level="3.1.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#why-do-we-take-samples"><i class="fa fa-check"></i><b>3.1.1</b> Why do we take samples?</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-normal-distribution"><i class="fa fa-check"></i><b>3.2</b> The Normal Distribution</a><ul>
<li class="chapter" data-level="3.2.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#pdf-of-a-normal-distribution"><i class="fa fa-check"></i><b>3.2.1</b> PDF of a Normal Distribution</a></li>
<li class="chapter" data-level="3.2.2" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-z-score"><i class="fa fa-check"></i><b>3.2.2</b> The Z-score</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-empirical-rule"><i class="fa fa-check"></i><b>3.3</b> The Empirical Rule</a></li>
<li class="chapter" data-level="3.4" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.4</b> The Central Limit Theorem</a><ul>
<li class="chapter" data-level="3.4.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#conditions-for-the-clt"><i class="fa fa-check"></i><b>3.4.1</b> Conditions for the CLT</a></li>
<li class="chapter" data-level="3.4.2" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#applying-the-cltclt-app"><i class="fa fa-check"></i><b>3.4.2</b> Applying the CLT</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#concluding-remark"><i class="fa fa-check"></i><b>3.5</b> Concluding Remark</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>4</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>4.1</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="4.1.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#the-null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>4.1.1</b> The Null and Alternative Hypotheses</a></li>
<li class="chapter" data-level="4.1.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#decision-errors"><i class="fa fa-check"></i><b>4.1.2</b> Decision Errors</a></li>
<li class="chapter" data-level="4.1.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#setting-up-hypotheses"><i class="fa fa-check"></i><b>4.1.3</b> Setting Up Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#simple-and-composite-hypotheses"><i class="fa fa-check"></i><b>4.2</b> Simple and Composite Hypotheses</a></li>
<li class="chapter" data-level="4.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#testing-hypotheses"><i class="fa fa-check"></i><b>4.3</b> Testing Hypotheses</a><ul>
<li class="chapter" data-level="4.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#using-a-critical-value-c"><i class="fa fa-check"></i><b>4.3.1</b> Using a Critical Value <span class="math inline">\(c\)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#visualizing-rejection-regions"><i class="fa fa-check"></i><b>4.3.2</b> Visualizing Rejection Regions</a></li>
<li class="chapter" data-level="4.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#the-p-value"><i class="fa fa-check"></i><b>4.3.3</b> The p-value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html"><i class="fa fa-check"></i><b>5</b> Z-tests, t-tests, and Confidence Intervals</a><ul>
<li class="chapter" data-level="5.1" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#starting-with-z"><i class="fa fa-check"></i><b>5.1</b> Starting with Z</a></li>
<li class="chapter" data-level="5.2" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#doing-a-z-test"><i class="fa fa-check"></i><b>5.2</b> Doing a Z-test</a><ul>
<li class="chapter" data-level="5.2.1" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#using-the-z-statistic"><i class="fa fa-check"></i><b>5.2.1</b> Using the Z Statistic</a></li>
<li class="chapter" data-level="5.2.2" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#p-values"><i class="fa fa-check"></i><b>5.2.2</b> p-values</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#students-t-distribution"><i class="fa fa-check"></i><b>5.3</b> Studentâs t-distribution</a></li>
<li class="chapter" data-level="5.4" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#confidence-intervals"><i class="fa fa-check"></i><b>5.4</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="5.4.1" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#what-are-confidence-intervals"><i class="fa fa-check"></i><b>5.4.1</b> What are confidence intervals?</a></li>
<li class="chapter" data-level="5.4.2" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#constructing-a-confidence-interval"><i class="fa fa-check"></i><b>5.4.2</b> Constructing a Confidence Interval</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing" class="section level1">
<h1><span class="header-section-number">Unit 4</span> Hypothesis Testing</h1>
<div id="hypothesis-testing-1" class="section level2">
<h2><span class="header-section-number">4.1</span> Hypothesis Testing</h2>
<p>Suppose one is interested in finding out whether one advertising method, say X, is more effective than a similar method Y in increasing the sales of a business. <strong>âIs method X more effective than method Y?â</strong></p>
<p>A simple way to answer this is to collect data for both Method X and Method Y. Suppose we randomly select a day or week, and count the number of sales attributable to each method during this period. We could then get the average of both methods and take the difference. We can say that Method X is better if the difference is positive, or worse if the difference is negative. This seems simple, but remember that the values will vary each time the data is collected. Hence, the difference in the averages will also be different and we cannot be 100% certain of the magnitude and direction of the difference.</p>
<p>With the uncertainties that are inherent in doing an experiment, how then can answer such questions as the one above in a principled way? The answer is <strong>Statistics</strong>.</p>
<p><strong>Hypothesis testing</strong> is a tool used to obtain statistical evidence to arrive at certain decisions given the data, accounting for uncertainty.</p>
<div id="the-null-and-alternative-hypotheses" class="section level3">
<h3><span class="header-section-number">4.1.1</span> The Null and Alternative Hypotheses</h3>
<p>Suppose we have a space <span class="math inline">\(\Omega\)</span> where all possible parameters <span class="math inline">\(\theta\)</span> about the data can be found. We can then divide this set into two mutually exclusive sets which we call <span class="math inline">\(\Omega_0\)</span> and <span class="math inline">\(\Omega_1\)</span>. We shall then denote <span class="math inline">\(H_0\)</span> as the hypothesis that <span class="math inline">\(\theta \in \Omega_0\)</span>, while <span class="math inline">\(H_1\)</span> is the hypothesis when <span class="math inline">\(\theta \in \Omega_1\)</span>. In statistical literature, these two hypotheses are called the <strong>null hypothesis</strong> and the <strong>alternative hypothesis</strong>, respectively.</p>
</div>
<div id="decision-errors" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Decision Errors</h3>
<p>Since there are two hypotheses and they are disjoint, only one hypothesis can be true. If the wrong hypothesis is taken to be true, a loss or cost is incurred.</p>
<p>Suppose that the <span class="math inline">\(\theta \in \Omega_0\)</span> or the null hypothesis is true, but it is rejected. This is called a <strong>Type I error</strong>. If instead
<span class="math inline">\(\theta \in \Omega_1\)</span> or the alternative hypothesis is true, but we do not reject the null hypothesis, we are making a <strong>Type II error</strong>.</p>
<p>For most cases, we can set our hypothesis test to have a certain Type I error rate, <span class="math inline">\(\alpha\)</span> (a number from 0 to 1), which corresponds to the probability of committing a Type I error. Thus, if we have a test with <span class="math inline">\(\alpha = 0.05\)</span>, it means that we have at most a <strong>5% chance</strong> of rejecting the null hypothesis when the null hypothesis is true.</p>
<p>The Type II error, which is denoted by <span class="math inline">\(\beta\)</span> and corresponds to not rejecting a false null hypothesis, is related to a concept called <strong>power</strong>. Statistical power is the probability of a hypothesis test of finding an effect if there is an effect to be found. Mathematically, power is computed as <span class="math inline">\(1 - \beta\)</span>. Experimental design includes what is called <strong>power analysis</strong>, which determines the appropriate sample size needed to detect the desired difference or effect. This is beyond the scope of the course, and will not be discussed further here.</p>
</div>
<div id="setting-up-hypotheses" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Setting Up Hypotheses</h3>
<p>Using the advertising example above, suppose that the hypothesis is <span class="math inline">\(\mu_X &gt; \mu_Y\)</span> with respect to sales, i.e.Â Method X generates more sales that Method Y. Analysts could claim that the data supports the theory that <span class="math inline">\(\mu_X &gt; \mu_Y\)</span>, when in fact <span class="math inline">\(\mu_X \leq \mu_Y\)</span> (Case 1). They could also mistakenly claim that data fails to support <span class="math inline">\(\mu_X\)</span> &gt; $_Y when it is true (Case 2). Both cases entail a rejection of the null hypothesis and for both situations, the setup of the null and alternative hypothesis are different, as shown below.</p>
<p>For Case 1:</p>
<p><span class="math display">\[
\begin{aligned}
  H_0 &amp;: \mu_{X} \leq \mu_{Y}\\
  H_1 &amp;: \mu_{X} &gt; \mu_{Y} 
\end{aligned}
\]</span></p>
<p>For Case 2:</p>
<p><span class="math display">\[
\begin{aligned}
  H_0 &amp;: \mu_{X} \geq \mu_{Y}\\
  H_1 &amp;: \mu_{X} &lt; \mu_{Y} 
\end{aligned}
\]</span></p>
<p>It is helpful to think about the consequence of mistakenly rejecting the null hypothesis, i.e., committing a type I error. In most business cases,
it is costly to introduce a new method as it will likely entail higher costs during implementation than retaining the old method. Thus, mistakenly rejecting the null hypothesis of Case 1 will be more costly to the business than 2 as Case 2 is about retaining the current strategy.</p>
<p>Intuitively, <span class="math inline">\(H_0\)</span> represents the status quo or current situation (âno differenceâ, hence the equality) and <span class="math inline">\(H_1\)</span> asserts that there is a difference. This is why in practice, <span class="math inline">\(H_0\)</span> <strong>must always</strong> contain some form of equality (<span class="math inline">\(=\)</span>, <span class="math inline">\(\leq\)</span>, <span class="math inline">\(\geq\)</span>) and <span class="math inline">\(H_1\)</span> must be stated in a way that complements <span class="math inline">\(H_0\)</span> exactly.</p>
<p><br></p>
</div>
</div>
<div id="simple-and-composite-hypotheses" class="section level2">
<h2><span class="header-section-number">4.2</span> Simple and Composite Hypotheses</h2>
<p>A <strong>simple hypothesis</strong> is where the parameter <span class="math inline">\(\theta\)</span> has only one value in either <span class="math inline">\(\Omega_0\)</span> or <span class="math inline">\(\Omega_1\)</span>. Such a setup is shown below:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \theta=\theta_0 \\
H_1&amp;: \theta \neq \theta_0
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\theta_0\)</span> is the parameter value of the null hypothesis set. Statistical tests that seek to test this hypothesis setup are called <strong>two-sided hypothesis tests</strong>.</p>
<p>A <strong>composite hypothesis</strong>, on the other hand, is a setup where the hypothesis space of either <span class="math inline">\(\Omega_0\)</span> or <span class="math inline">\(\Omega_1\)</span> contains more than one value for <span class="math inline">\(\theta_0\)</span>. There are two ways to set up a composite hypothesis and the difference lies in the inequality sign used. One could either do:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \theta\leq\theta_0 \\
H_1&amp;: \theta &gt; \theta_0
\end{aligned}
\]</span></p>
<p>or the opposite which is:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \theta\geq\theta_0 \\
H_1&amp;: \theta &lt; \theta_0
\end{aligned}
\]</span></p>
<p>Statistical tests for composite hypotheses are called <strong>one-sided tests</strong> and, depending on the inequality sign of the alternative hypothesis, it can either be called a <strong>right-tailed</strong> (first) or a <strong>left-tailed test</strong> (second).</p>
<p><br></p>
</div>
<div id="testing-hypotheses" class="section level2">
<h2><span class="header-section-number">4.3</span> Testing Hypotheses</h2>
<div id="using-a-critical-value-c" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Using a Critical Value <span class="math inline">\(c\)</span></h3>
<p>In doing a hypothesis test, we either decide to <strong>reject</strong> or <strong>not reject</strong> the null hypothesis. To do so, we need to define a statistic <span class="math inline">\(T\)</span> as the âdistanceâ between the sample statistic and <span class="math inline">\(\theta_0\)</span>. <span class="math inline">\(T\)</span> is thus random (as our data is a random sample of our population). Given a particular value of <span class="math inline">\(\theta_0\)</span>, we might want to have a threshold <span class="math inline">\(c\)</span>, which we will call the <strong>critical value</strong>. Using <span class="math inline">\(c\)</span> we can decide to reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(T \geq c\)</span>, or not reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(T &lt; c\)</span>. Each threshold corresponds to a value of <span class="math inline">\(\alpha\)</span>.</p>
<p>The correct way of testing hypotheses is to set the <span class="math inline">\(\alpha\)</span> first and then use the corresponding critical value <span class="math inline">\(c\)</span>. The mathematics behind this is ommitted for now as it can get quite overwhelming. If this has piqued curiosity, however, a number of introductory statistics texts and resources on the Internet explore the mathematical underpinnings of hypothesis testing in detail. The applications of this concept will be shown in the unit on z-tests and t-tests.</p>
<p><br></p>
</div>
<div id="visualizing-rejection-regions" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Visualizing Rejection Regions</h3>
<p>Values that are greater than or equal to a certain threshold <span class="math inline">\(c\)</span> that intersect with the alternative hypothesis parameter space <span class="math inline">\(\Omega_1\)</span> are contained within the <strong>rejection region</strong>. Rejection regions in the visualizations below are colored in <strong>blue</strong>.</p>
<p>For a <em>two-sided hypothesis test</em>, we reject on both tails for a symmetric distribution (usually a normal distribution). This is so since an extremely high or low sample statistic can be evidence for us to reject <span class="math inline">\(H_0\)</span> (as implied by the <span class="math inline">\(\neq\)</span> sign). Since the probability of rejecting a true <span class="math inline">\(H_0\)</span> supposedly covers both high and low values, the critical value <span class="math inline">\(c\)</span> to be used should correspond to <span class="math inline">\(\alpha/2\)</span>, <strong>not</strong> <span class="math inline">\(\alpha\)</span>.</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-18-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>For <em>one-sided tests</em>, we reject depending on the parameter space of the alternate hypothesis. Hence, the rejection region for a <em>left-tailed test</em> can be shown as:</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-19-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The rejection region for a <em>right-tailed test</em> is shown below:</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="the-p-value" class="section level3">
<h3><span class="header-section-number">4.3.3</span> The p-value</h3>
<p>Another important concept is the <strong>p-value</strong> which is often reported in analyses to denote statistical significance relative to a set <span class="math inline">\(\alpha\)</span> (usually 0.05). It is defined as the probability of obtaining test results at least as extreme as the results actually observed when <span class="math inline">\(H_0\)</span> is true.</p>
<p>It can be thought of as a measure of how âsurprisedâ you are with the data. Higher values mean that the data is not at all surprising relative to the null hypothesis. Although this might be the case, p-values do not dictate the probability that the null hypothesis is true given the data, and cannot be used to draw conclusions on how likely the null hypothesis is compared to the alternative, and vice versa. It only allows one to decide whether or not to reject <span class="math inline">\(H_0\)</span>.</p>
<p>Nonetheless, we can by definition, use p-values to test for hypothesis. This is done by calculating the p-value and comparing it with a set <span class="math inline">\(\alpha\)</span> level. We reject the null hypothesis if the p-value <span class="math inline">\(p \leq \alpha\)</span>.</p>
<p><br></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-normal-distribution-and-the-central-limit-theorem.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="z-tests-t-tests-and-confidence-intervals.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
  
