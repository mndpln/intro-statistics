<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Unit 3 The Normal Distribution and the Central Limit Theorem | An Introduction to Statistics</title>
  <meta name="description" content="Unit 3 The Normal Distribution and the Central Limit Theorem | An Introduction to Statistics" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Unit 3 The Normal Distribution and the Central Limit Theorem | An Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="mndpln/intro-statistics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Unit 3 The Normal Distribution and the Central Limit Theorem | An Introduction to Statistics" />
  
  
  

<meta name="author" content="Mariefel Nicole Deypalan" />


<meta name="date" content="2021-04-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability-and-probability-distributions.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="lib/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="lib/css/style.css" type="text/css" />
<link rel="stylesheet" href="lib/css/lesson.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">An Introduction to Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-data.html"><a href="introduction-to-data.html"><i class="fa fa-check"></i><b>1</b> Introduction to Data</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#what-is-data"><i class="fa fa-check"></i><b>1.1</b> What is Data?</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#types-of-data"><i class="fa fa-check"></i><b>1.2</b> Types of Data</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-data.html"><a href="introduction-to-data.html#homework-1"><i class="fa fa-check"></i><b>1.3</b> Homework 1</a></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-data.html"><a href="introduction-to-data.html#measures-of-central-tendencymct-wiki"><i class="fa fa-check"></i><b>1.4</b> Measures of Central Tendency</a></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-data.html"><a href="introduction-to-data.html#measures-of-variability"><i class="fa fa-check"></i><b>1.5</b> Measures of Variability</a></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-data.html"><a href="introduction-to-data.html#examining-numerical-data"><i class="fa fa-check"></i><b>1.6</b> Examining Numerical Data</a><ul>
<li class="chapter" data-level="1.6.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#numerical-methods"><i class="fa fa-check"></i><b>1.6.1</b> Numerical Methods</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#graphical-methods"><i class="fa fa-check"></i><b>1.6.2</b> Graphical Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction-to-data.html"><a href="introduction-to-data.html#examining-categorical-data"><i class="fa fa-check"></i><b>1.7</b> Examining Categorical Data</a><ul>
<li class="chapter" data-level="1.7.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#tabular-methods"><i class="fa fa-check"></i><b>1.7.1</b> Tabular Methods</a></li>
<li class="chapter" data-level="1.7.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#graphical-methods-1"><i class="fa fa-check"></i><b>1.7.2</b> Graphical Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="introduction-to-data.html"><a href="introduction-to-data.html#prelude-some-number-theory"><i class="fa fa-check"></i><b>1.8</b> Prelude: Some Number Theory</a><ul>
<li class="chapter" data-level="1.8.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#the-factorial"><i class="fa fa-check"></i><b>1.8.1</b> The Factorial</a></li>
<li class="chapter" data-level="1.8.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#combinations"><i class="fa fa-check"></i><b>1.8.2</b> Combinations</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="introduction-to-data.html"><a href="introduction-to-data.html#references"><i class="fa fa-check"></i><b>1.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html"><i class="fa fa-check"></i><b>2</b> Probability and Probability Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#defining-probability"><i class="fa fa-check"></i><b>2.1</b> Defining Probability</a></li>
<li class="chapter" data-level="2.2" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#homework-1-1"><i class="fa fa-check"></i><b>2.2</b> Homework 1</a></li>
<li class="chapter" data-level="2.3" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#independence"><i class="fa fa-check"></i><b>2.3</b> Independence</a></li>
<li class="chapter" data-level="2.4" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#random-variables"><i class="fa fa-check"></i><b>2.4</b> Random Variables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#discrete-and-continuous"><i class="fa fa-check"></i><b>2.4.1</b> Discrete and Continuous</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#homework-2"><i class="fa fa-check"></i><b>2.5</b> Homework 2</a></li>
<li class="chapter" data-level="2.6" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#the-uniform-distribution"><i class="fa fa-check"></i><b>2.6</b> The Uniform Distribution</a></li>
<li class="chapter" data-level="2.7" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#the-binomial-distribution"><i class="fa fa-check"></i><b>2.7</b> The Binomial Distribution</a><ul>
<li class="chapter" data-level="2.7.1" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#bernoulli-trial"><i class="fa fa-check"></i><b>2.7.1</b> Bernoulli Trial</a></li>
<li class="chapter" data-level="2.7.2" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#pmf-of-a-binomial-distributionma151"><i class="fa fa-check"></i><b>2.7.2</b> PMF of a Binomial Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#homework-3"><i class="fa fa-check"></i><b>2.8</b> Homework 3</a></li>
<li class="chapter" data-level="2.9" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#references-1"><i class="fa fa-check"></i><b>2.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html"><i class="fa fa-check"></i><b>3</b> The Normal Distribution and the Central Limit Theorem</a><ul>
<li class="chapter" data-level="3.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#population-vs.-sample"><i class="fa fa-check"></i><b>3.1</b> Population vs. Sample</a></li>
<li class="chapter" data-level="3.2" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-normal-distribution"><i class="fa fa-check"></i><b>3.2</b> The Normal Distribution</a><ul>
<li class="chapter" data-level="3.2.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#pdf-of-a-normal-distribution"><i class="fa fa-check"></i><b>3.2.1</b> PDF of a Normal Distribution</a></li>
<li class="chapter" data-level="3.2.2" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-z-score"><i class="fa fa-check"></i><b>3.2.2</b> The Z-score</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-empirical-rule"><i class="fa fa-check"></i><b>3.3</b> The Empirical Rule</a></li>
<li class="chapter" data-level="3.4" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.4</b> The Central Limit Theorem</a><ul>
<li class="chapter" data-level="3.4.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#applying-the-cltclt-app"><i class="fa fa-check"></i><b>3.4.1</b> Applying the CLT</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#confidence-intervals"><i class="fa fa-check"></i><b>3.5</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="3.5.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#what-are-confidence-intervals"><i class="fa fa-check"></i><b>3.5.1</b> What are confidence intervals?</a></li>
<li class="chapter" data-level="3.5.2" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#constructing-a-confidence-interval"><i class="fa fa-check"></i><b>3.5.2</b> Constructing a Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#concluding-remark"><i class="fa fa-check"></i><b>3.6</b> Concluding Remark</a></li>
<li class="chapter" data-level="3.7" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#references-2"><i class="fa fa-check"></i><b>3.7</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-normal-distribution-and-the-central-limit-theorem" class="section level1">
<h1><span class="header-section-number">Unit 3</span> The Normal Distribution and the Central Limit Theorem</h1>
<div id="population-vs.-sample" class="section level2">
<h2><span class="header-section-number">3.1</span> Population vs. Sample</h2>
<p><strong>Population</strong> - all the elements from a set of data<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a><br />
<strong>Sample</strong> - one or more observations taken from the population</p>
<p>A quantity taken for the entire population is known as a population <strong>parameter</strong>, while that taken for a sample is called a <strong>sample statistic</strong>.</p>
<p><br></p>
<p><strong>Sampling distribution</strong></p>
<ul>
<li>“The sampling distribution of a statistic is a probability distribution based on a large number of samples of size <span class="math inline">\(n\)</span> from a given population.”<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a></li>
</ul>
<p>This means that…</p>
<ul>
<li>The sampling distribution is a probability distribution.<br />
</li>
<li>From the population, many samples of the same size are taken and a statistic (e.g mean, proportion) is taken for each sample.<br />
</li>
<li>Using the values of the statistic that were calculated from the samples, a distribution is then obtained.</li>
</ul>
<p><br></p>
<p><strong>Standard Error</strong></p>
<ul>
<li>The measure of the variability of the sample means<br />
</li>
<li><span class="math inline">\(SE = \frac{\sigma}{\sqrt{n}}\)</span>, <span class="math inline">\(\sigma\)</span> is the population standard deviation</li>
</ul>
<p><br></p>
</div>
<div id="the-normal-distribution" class="section level2">
<h2><span class="header-section-number">3.2</span> The Normal Distribution</h2>
<p>The normal distribution is the most common among all probability distributions, perhaps because it describes a lot of variables quite well. According to an introductory statistics book, “Many variables are nearly normal, but none are exactly normal. Thus the normal distribution, while not perfect for any single problem, is very useful for a variety of problems.”<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></p>
<p>The normal distribution is bell-shaped. It is symmetric and unimodal; it has one peak and tapers off at both ends in exactly the same way. Below is an example of a normal distribution with a mean of 2 and a standard deviation of 1.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1">z &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>, <span class="dt">b =</span> <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb5-2" title="2"><span class="kw">plot</span>(z, <span class="kw">dnorm</span>(z, <span class="dt">mean =</span> <span class="dv">2</span>, <span class="dt">sd =</span> <span class="dv">1</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">ylab =</span> <span class="st">&quot;density&quot;</span>, </a>
<a class="sourceLine" id="cb5-3" title="3">    <span class="dt">axes =</span> <span class="ot">FALSE</span>, <span class="dt">main =</span> <span class="st">&quot;Normal Distribution, mean = 2, sd = 1&quot;</span>)</a>
<a class="sourceLine" id="cb5-4" title="4"><span class="kw">box</span>(<span class="dt">bty =</span> <span class="st">&quot;l&quot;</span>)</a>
<a class="sourceLine" id="cb5-5" title="5"><span class="kw">axis</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb5-6" title="6"><span class="kw">axis</span>(<span class="dv">1</span>)</a></code></pre></div>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br></p>
<p>Two parameters are used to describe the normal distribution - mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. A mean of 0 and a standard deviation of 1 corresponds to the standard normal distribution which is shown below:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1">z &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dt">length =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb6-2" title="2"><span class="kw">plot</span>(z, <span class="kw">dnorm</span>(z), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">ylab =</span> <span class="st">&quot;density&quot;</span>, <span class="dt">axes =</span> <span class="ot">FALSE</span>, </a>
<a class="sourceLine" id="cb6-3" title="3">    <span class="dt">main =</span> <span class="st">&quot;Standard Normal Distribution)&quot;</span>)</a>
<a class="sourceLine" id="cb6-4" title="4"><span class="kw">box</span>(<span class="dt">bty =</span> <span class="st">&quot;l&quot;</span>)</a>
<a class="sourceLine" id="cb6-5" title="5"><span class="kw">axis</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb6-6" title="6"><span class="kw">axis</span>(<span class="dv">1</span>)</a></code></pre></div>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br></p>
<div id="pdf-of-a-normal-distribution" class="section level3">
<h3><span class="header-section-number">3.2.1</span> PDF of a Normal Distribution</h3>
<p>The normal distribution is continuous, i.e. a normally distributed random variable can take on any value between <span class="math inline">\((-\infty, +\infty)\)</span>. The continuous analog of pmfs are pdfs or <strong>probability density functions</strong> and thus, the pdf for the normal distribution is:</p>
<p><span class="math display">\[f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}}\exp{\left[-\frac{1}{2} \cdot \left( \frac{x - \mu}{\sigma}\right)^2\right]}\]</span></p>
<p><br></p>
</div>
<div id="the-z-score" class="section level3">
<h3><span class="header-section-number">3.2.2</span> The Z-score</h3>
<ul>
<li>measures how many standard deviations above or below the mean a data point is</li>
</ul>
<p>Formula for the <strong>z-score</strong>:</p>
<p><span class="math display">\[z = \frac{x-\mu}{\sigma}\]</span></p>
<p>The above equation looks like the last part of the normal pdf. Substituting this expression for z yields:</p>
<p><span class="math display">\[f(z) = \frac{1}{\sqrt{2 \pi \sigma^2}}\exp{\left[-\frac{1}{2} \cdot z^2\right]}\]</span></p>
<p>This is the equation for the <strong>standard normal distribution</strong>.</p>
<p>These equations are rarely used to compute probabilities because various software have made these available through the use of functions. For example, the Excel function <code>NORMDIST()</code><a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> gives the exact value of the pdf for any normal distribution specified by a mean and standard deviation. However, introducing these concepts is still important to justify the robustness of the statistical tools that will be discussed later on. Knowing these fundamental concepts allows one to confidently use and interpret the results of many different methods such as hypothesis testing, linear regression, etc.</p>
<p><br></p>
</div>
</div>
<div id="the-empirical-rule" class="section level2">
<h2><span class="header-section-number">3.3</span> The Empirical Rule</h2>
<p>Another useful property of normally distributed data is given by the <strong>empirical rule</strong>. Given that the distribution of the data is bell-shaped, this rule states that:</p>
<ul>
<li>Approximately 68% of the data lie within 1 standard deviation from the mean<br />
</li>
<li>Approximately 95% of the data, 2 standard deviations<br />
</li>
<li>About 99.7% of the data, 3 standard deviations</li>
</ul>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1">knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;empirical-rule.jpg&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-16"></span>
<img src="empirical-rule.jpg" alt="The Empirical Rule" width="75%" />
<p class="caption">
Figure 3.1: The Empirical Rule
</p>
</div>
<p><br></p>
</div>
<div id="the-central-limit-theorem" class="section level2">
<h2><span class="header-section-number">3.4</span> The Central Limit Theorem</h2>
<p>The Central Limit Theorem (CLT) states that for a population with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, taking sufficiently large random samples with replacement and computing sample means will yield a distribution of sample means that is approximately normal.<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a></p>
<p>The CLT holds true provided that the following conditions are met:</p>
<ol style="list-style-type: decimal">
<li><strong>Independence</strong>: The sampled observations must be independent.<br />
</li>
<li><strong>Sample size/skew</strong>: If the population is skewed, the sample size <span class="math inline">\(n\)</span> must be greater than 3. If not, the population distribution must be normal.</li>
</ol>
<p><br></p>
<div id="applying-the-cltclt-app" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Applying the CLT<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a></h3>
<div class="prob">
<p>Suppose my iPod has 3,000 songs. I know that the distribution of lengths of these songs is right-skewed, and for this iPod, the mean length is 3.45 minutes and the standard deviation is 1.63 minutes.</p>
<p>I’m about to take a trip to visit my parents and the drive is 6 hours. I make a random playlist of 100 songs. What is the probability that my playlist lasts the entire drive?</p>
</div>
<p><br></p>
<p>Given:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> = 3.45 minutes<br />
</li>
<li><span class="math inline">\(\sigma\)</span> = 1.63 minutes<br />
</li>
<li>6 hours = 360 minutes</li>
</ul>
<p>Find:</p>
<ul>
<li>probability that 100 <em>randomly</em> selected songs lasts 360 minutes, which is the same as<br />
</li>
<li>probability that the average length of the 100 <em>randomly</em> selected songs is at least <span class="math inline">\(360/100 = 3.6\)</span> minutes<br />
</li>
<li><span class="math inline">\(P(\overline{X} \geq 3.6)\)</span></li>
</ul>
<p>According to the CLT:</p>
<p><span class="math display">\[\overline{X} \sim N(\mu = 3.45, ~ \text{SE} = \frac{1.63}{100} = 0.163)\]</span></p>
<p><span class="math display">\[Z = \frac{x - \mu}{\sigma} = \frac{3.6 - 3.45}{0.163} = 0.92\]</span></p>
<p><span class="math display">\[P(Z \geq 0.92) = 0.1788\]</span></p>
<p><br></p>
</div>
</div>
<div id="confidence-intervals" class="section level2">
<h2><span class="header-section-number">3.5</span> Confidence Intervals</h2>
<div id="what-are-confidence-intervals" class="section level3">
<h3><span class="header-section-number">3.5.1</span> What are confidence intervals?</h3>
<p>Confidence intervals give us a range of plausible values for the population parameter based on results from a sample. The conditions for the CLT must also be met for the confidence interval to be valid.</p>
</div>
<div id="constructing-a-confidence-interval" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Constructing a Confidence Interval</h3>
<p>The confidence interval <strong>for the mean</strong> is computed as:</p>
<p><span class="math display">\[(\overline{x} - z^* \frac{s}{\sqrt{n}}, ~ \overline{x} + z^* \frac{s}{\sqrt{n}})\]</span></p>
<ul>
<li><span class="math inline">\(\overline{x}\)</span> is the sample mean<br />
</li>
<li><span class="math inline">\(s\)</span> is the sample mean<br />
</li>
<li><span class="math inline">\(n\)</span> is the sample size<br />
</li>
<li><span class="math inline">\(z^*\)</span> is the critical z-score</li>
</ul>
<p><br></p>
</div>
</div>
<div id="concluding-remark" class="section level2">
<h2><span class="header-section-number">3.6</span> Concluding Remark</h2>
<p>This unit has introduced one of the most important theorems in statistics and in doing so, has inevitably scratched the surface of one of the most fundamental inferential methods - <strong>hypothesis testing</strong>. The next unit will more formally introduce the rudiments of hypothesis testing - from setting up hypotheses to selecting the appropriate confidence level. After establishing the fundamental definitions, applications and examples will be presented which will hopefully solidify the previous discussions. The normal distribution will be re-introduced and in the context of hypothesis testing, its ubiquity in the realm of inferential statistics will be more apparent.</p>
<p><br></p>
</div>
<div id="references-2" class="section level2">
<h2><span class="header-section-number">3.7</span> References</h2>

</div>
</div>



























<div class="footnotes">
<hr />
<ol start="17">
<li id="fn17"><p><a href="https://stattrek.com/sampling/populations-and-samples.aspx">Populations and Samples</a>.<a href="the-normal-distribution-and-the-central-limit-theorem.html#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p><a href="https://online.stat.psu.edu/stat500/lesson/4">Sampling Distributions</a>.<a href="the-normal-distribution-and-the-central-limit-theorem.html#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p>Diez, D., Centinkaya-Rundel, M., &amp; Barr, C. (2019). OpenIntro Statistics. OpenIntro.<a href="the-normal-distribution-and-the-central-limit-theorem.html#fnref19" class="footnote-back">↩</a></p></li>
<li id="fn20"><p><a href="https://corporatefinanceinstitute.com/resources/excel/functions/normdist-excel-normal-distribution/">NORMDIST Function</a>.<a href="the-normal-distribution-and-the-central-limit-theorem.html#fnref20" class="footnote-back">↩</a></p></li>
<li id="fn21"><p><a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_probability/BS704_Probability12.html">Central Limit Theorem</a>.<a href="the-normal-distribution-and-the-central-limit-theorem.html#fnref21" class="footnote-back">↩</a></p></li>
<li id="fn22"><p>Inferential Statistics, Coursera.<a href="the-normal-distribution-and-the-central-limit-theorem.html#fnref22" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability-and-probability-distributions.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
