<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Unit 5 Z-tests, t-tests, and Confidence Intervals | An Introduction to Statistics</title>
  <meta name="description" content="Unit 5 Z-tests, t-tests, and Confidence Intervals | An Introduction to Statistics" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Unit 5 Z-tests, t-tests, and Confidence Intervals | An Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="mndpln/intro-statistics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Unit 5 Z-tests, t-tests, and Confidence Intervals | An Introduction to Statistics" />
  
  
  

<meta name="author" content="Mariefel Nicole Deypalan" />


<meta name="date" content="2021-05-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="hypothesis-testing.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>



<link rel="stylesheet" href="lib/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="lib/css/style.css" type="text/css" />
<link rel="stylesheet" href="lib/css/lesson.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">An Introduction to Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-data.html"><a href="introduction-to-data.html"><i class="fa fa-check"></i><b>1</b> Introduction to Data</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#what-is-data"><i class="fa fa-check"></i><b>1.1</b> What is Data?</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#types-of-data"><i class="fa fa-check"></i><b>1.2</b> Types of Data</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-data.html"><a href="introduction-to-data.html#homework"><i class="fa fa-check"></i><b>1.3</b> Homework</a></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-data.html"><a href="introduction-to-data.html#measures-of-central-tendencymct-wiki"><i class="fa fa-check"></i><b>1.4</b> Measures of Central Tendency</a></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-data.html"><a href="introduction-to-data.html#measures-of-variability"><i class="fa fa-check"></i><b>1.5</b> Measures of Variability</a></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-data.html"><a href="introduction-to-data.html#examining-numerical-data"><i class="fa fa-check"></i><b>1.6</b> Examining Numerical Data</a><ul>
<li class="chapter" data-level="1.6.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#numerical-methods"><i class="fa fa-check"></i><b>1.6.1</b> Numerical Methods</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#graphical-methods"><i class="fa fa-check"></i><b>1.6.2</b> Graphical Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction-to-data.html"><a href="introduction-to-data.html#examining-categorical-data"><i class="fa fa-check"></i><b>1.7</b> Examining Categorical Data</a><ul>
<li class="chapter" data-level="1.7.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#tabular-methods"><i class="fa fa-check"></i><b>1.7.1</b> Tabular Methods</a></li>
<li class="chapter" data-level="1.7.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#graphical-methods-1"><i class="fa fa-check"></i><b>1.7.2</b> Graphical Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="introduction-to-data.html"><a href="introduction-to-data.html#aside-some-number-theory"><i class="fa fa-check"></i><b>1.8</b> Aside: Some Number Theory</a><ul>
<li class="chapter" data-level="1.8.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#the-factorial"><i class="fa fa-check"></i><b>1.8.1</b> The Factorial</a></li>
<li class="chapter" data-level="1.8.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#combinations"><i class="fa fa-check"></i><b>1.8.2</b> Combinations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html"><i class="fa fa-check"></i><b>2</b> Probability and Probability Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#defining-probability"><i class="fa fa-check"></i><b>2.1</b> Defining Probability</a></li>
<li class="chapter" data-level="2.2" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#homework-1"><i class="fa fa-check"></i><b>2.2</b> Homework 1</a></li>
<li class="chapter" data-level="2.3" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#independence"><i class="fa fa-check"></i><b>2.3</b> Independence</a></li>
<li class="chapter" data-level="2.4" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#random-variables"><i class="fa fa-check"></i><b>2.4</b> Random Variables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#discrete-and-continuous"><i class="fa fa-check"></i><b>2.4.1</b> Discrete and Continuous</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#homework-2"><i class="fa fa-check"></i><b>2.5</b> Homework 2</a></li>
<li class="chapter" data-level="2.6" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#pmfs-and-pdfs"><i class="fa fa-check"></i><b>2.6</b> PMFs and PDFs</a></li>
<li class="chapter" data-level="2.7" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#the-uniform-distribution"><i class="fa fa-check"></i><b>2.7</b> The Uniform Distribution</a></li>
<li class="chapter" data-level="2.8" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#the-binomial-distribution"><i class="fa fa-check"></i><b>2.8</b> The Binomial Distribution</a><ul>
<li class="chapter" data-level="2.8.1" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#bernoulli-trial"><i class="fa fa-check"></i><b>2.8.1</b> Bernoulli Trial</a></li>
<li class="chapter" data-level="2.8.2" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#pmf-of-a-binomial-distributionma151"><i class="fa fa-check"></i><b>2.8.2</b> PMF of a Binomial Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="probability-and-probability-distributions.html"><a href="probability-and-probability-distributions.html#homework-3"><i class="fa fa-check"></i><b>2.9</b> Homework 3</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html"><i class="fa fa-check"></i><b>3</b> The Normal Distribution and the Central Limit Theorem</a><ul>
<li class="chapter" data-level="3.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#population-vs.-sample"><i class="fa fa-check"></i><b>3.1</b> Population vs. Sample</a><ul>
<li class="chapter" data-level="3.1.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#why-do-we-take-samples"><i class="fa fa-check"></i><b>3.1.1</b> Why do we take samples?</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-normal-distribution"><i class="fa fa-check"></i><b>3.2</b> The Normal Distribution</a><ul>
<li class="chapter" data-level="3.2.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#pdf-of-a-normal-distribution"><i class="fa fa-check"></i><b>3.2.1</b> PDF of a Normal Distribution</a></li>
<li class="chapter" data-level="3.2.2" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-z-score"><i class="fa fa-check"></i><b>3.2.2</b> The Z-score</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-empirical-rule"><i class="fa fa-check"></i><b>3.3</b> The Empirical Rule</a></li>
<li class="chapter" data-level="3.4" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.4</b> The Central Limit Theorem</a><ul>
<li class="chapter" data-level="3.4.1" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#conditions-for-the-clt"><i class="fa fa-check"></i><b>3.4.1</b> Conditions for the CLT</a></li>
<li class="chapter" data-level="3.4.2" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#applying-the-cltclt-app"><i class="fa fa-check"></i><b>3.4.2</b> Applying the CLT</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="the-normal-distribution-and-the-central-limit-theorem.html"><a href="the-normal-distribution-and-the-central-limit-theorem.html#concluding-remark"><i class="fa fa-check"></i><b>3.5</b> Concluding Remark</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>4</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#basic-concepts"><i class="fa fa-check"></i><b>4.1</b> Basic Concepts</a><ul>
<li class="chapter" data-level="4.1.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#the-null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>4.1.1</b> The Null and Alternative Hypotheses</a></li>
<li class="chapter" data-level="4.1.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#decision-errors"><i class="fa fa-check"></i><b>4.1.2</b> Decision Errors</a></li>
<li class="chapter" data-level="4.1.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#setting-up-hypotheses"><i class="fa fa-check"></i><b>4.1.3</b> Setting Up Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#simple-and-composite-hypotheses"><i class="fa fa-check"></i><b>4.2</b> Simple and Composite Hypotheses</a></li>
<li class="chapter" data-level="4.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#testing-hypotheses"><i class="fa fa-check"></i><b>4.3</b> Testing Hypotheses</a><ul>
<li class="chapter" data-level="4.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#using-a-critical-value-c"><i class="fa fa-check"></i><b>4.3.1</b> Using a Critical Value <span class="math inline">\(c\)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#visualizing-rejection-regions"><i class="fa fa-check"></i><b>4.3.2</b> Visualizing Rejection Regions</a></li>
<li class="chapter" data-level="4.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#the-p-value"><i class="fa fa-check"></i><b>4.3.3</b> The p-value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html"><i class="fa fa-check"></i><b>5</b> Z-tests, t-tests, and Confidence Intervals</a><ul>
<li class="chapter" data-level="5.1" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#starting-with-z"><i class="fa fa-check"></i><b>5.1</b> Starting with Z</a></li>
<li class="chapter" data-level="5.2" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#doing-a-z-test"><i class="fa fa-check"></i><b>5.2</b> Doing a Z-test</a><ul>
<li class="chapter" data-level="5.2.1" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#using-the-z-statistic"><i class="fa fa-check"></i><b>5.2.1</b> Using the Z Statistic</a></li>
<li class="chapter" data-level="5.2.2" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#p-values"><i class="fa fa-check"></i><b>5.2.2</b> p-values</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#students-t-distribution"><i class="fa fa-check"></i><b>5.3</b> Student’s t-distribution</a></li>
<li class="chapter" data-level="5.4" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#a-simple-t-test-example"><i class="fa fa-check"></i><b>5.4</b> A Simple t-test Example</a></li>
<li class="chapter" data-level="5.5" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#tests-for-composite-hypotheses"><i class="fa fa-check"></i><b>5.5</b> Tests for Composite Hypotheses</a><ul>
<li class="chapter" data-level="5.5.1" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#rejection-regions"><i class="fa fa-check"></i><b>5.5.1</b> Rejection Regions</a></li>
<li class="chapter" data-level="5.5.2" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#calculating-p-values"><i class="fa fa-check"></i><b>5.5.2</b> Calculating p-values</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#a-two-sample-t-test"><i class="fa fa-check"></i><b>5.6</b> A Two-Sample t-test</a></li>
<li class="chapter" data-level="5.7" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#hypothesis-testing-examples"><i class="fa fa-check"></i><b>5.7</b> Hypothesis Testing Examples</a><ul>
<li class="chapter" data-level="5.7.1" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#problem-1"><i class="fa fa-check"></i><b>5.7.1</b> Problem 1</a></li>
<li class="chapter" data-level="5.7.2" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#problem-2"><i class="fa fa-check"></i><b>5.7.2</b> Problem 2</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#confidence-intervals"><i class="fa fa-check"></i><b>5.8</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="5.8.1" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#what-are-confidence-intervals"><i class="fa fa-check"></i><b>5.8.1</b> What are confidence intervals?</a></li>
<li class="chapter" data-level="5.8.2" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#constructing-a-confidence-interval"><i class="fa fa-check"></i><b>5.8.2</b> Constructing a Confidence Interval</a></li>
<li class="chapter" data-level="5.8.3" data-path="z-tests-t-tests-and-confidence-intervals.html"><a href="z-tests-t-tests-and-confidence-intervals.html#interpreting-the-confidence-interval"><i class="fa fa-check"></i><b>5.8.3</b> Interpreting the Confidence Interval</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="z-tests-t-tests-and-confidence-intervals" class="section level1">
<h1><span class="header-section-number">Unit 5</span> Z-tests, t-tests, and Confidence Intervals</h1>
<style>
.prob {
  color: gray;
  font-size:110%;
  border: 2px solid gray;
  border-radius: 5px;
  padding-left: 20px;
  padding-right: 20px;
  padding-top: 10px;
  padding-bottom: 10px;
}
</style>
<div id="starting-with-z" class="section level2">
<h2><span class="header-section-number">5.1</span> Starting with Z</h2>
<p>The standard normal distribution, as discussed in Unit 3, is also called the Z Distribution because the process of <strong>standardization</strong> yields a random variable commonly called <span class="math inline">\(Z\)</span>.</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="doing-a-z-test" class="section level2">
<h2><span class="header-section-number">5.2</span> Doing a Z-test</h2>
<p>Now that we have been introduced to the Z Distribution and the hypothesis testing framework, we are now ready to answer questions like, <strong>“Is there evidence to conclude that the mean of a population is equal to a certain number?”</strong></p>
<div id="using-the-z-statistic" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Using the Z Statistic</h3>
<div class="prob">
<p>Suppose a pasta company claims that the net weight of one pack of pasta is 100 g, with a standard deviation of 0.5 g. You are hired by this company to do statistical analysis for them, specifically to test whether the 1 million packs of pasta produced this week meet their 100-gram claim. You cannot weigh all the 1 million packs individually because reopening them would cost the company money, and it would obviously take you a very long time to weigh each pack. The manager of the manufacturing division gives you 500 packs of pasta to work with and hopes that with your statistical knowledge, you will be able to prove or dispute their claim. What should you do?</p>
</div>
<p><br></p>
<p>The problem above can be solved using a simple hypothesis setup:</p>
<p><span class="math display">\[
\begin{aligned}
  H_0 &amp;: \mu = \mu_0 \\
  H_1 &amp;: \mu \neq \mu_0
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the true mean of the population, and <span class="math inline">\(\mu_0\)</span> is the reference mean. In the problem, the reference mean is 100 g, since that is what the company claims. The population, whose true mean is <span class="math inline">\(\mu\)</span>, is the batch of 1 million packs produced during the week. Using statistical jargon, we would like to test whether the population mean is indeed 100 g using the sample of 500 pasta packs. Recall that the sample mean, <span class="math inline">\(\overline{X}\)</span>, is an estimate of <span class="math inline">\(\mu\)</span>. Hence, taking the mean of the 500 packs of pasta would give an estimate of the true mean weight of the batch produced. <span class="math inline">\(\overline{X}\)</span> is simply the arithmetic average of the weights of the 500 packs, i.e., <span class="math inline">\(\overline{X} = \sum_i^{n}\frac{x_i}{n}\)</span>. To test this hypothesis, we can take the difference between <span class="math inline">\(\overline{X}\)</span> and <span class="math inline">\(\mu_0\)</span> and check if it is large enough to say that the population mean <span class="math inline">\(\mu\)</span> is not 100 g. Note that the direction of the difference (i.e. whether it is positive or negative) does not matter as implied by the hypotheses. Thus, from Unit 4, we can reject the null hypothesis when:</p>
<p><span class="math display">\[|\overline{X} - \mu_0| \geq c\]</span></p>
<p>where <span class="math inline">\(c\)</span> is the <em>critical value</em>. At this point, one might be tempted to choose an arbitrary value for <span class="math inline">\(c\)</span>, say 10 or 15. That would undermine the integrity of the procedure performed. Recall from the previous discussion that the appropriate <span class="math inline">\(c\)</span> is determined by first setting an <span class="math inline">\(\alpha\)</span>.</p>
<p>For this problem, assume that the company would like to be 95% sure that the batch produced meets their 100-gram claim. Given this 95% confidence level, <span class="math inline">\(\alpha\)</span> would have a value of 0.05 since we can only allow incorrect rejection of <span class="math inline">\(H_0\)</span> 5% of the time. This is a two-tailed test and hence, the critical value to be used should correspond to <span class="math inline">\(\alpha/2\)</span>.</p>
<p>What is the appropriate critical value to use? We have 500 samples, a sufficiently large number, and it would be safe to say that the samples are independent. Since the assumptions are met, we can use the <strong>Central Limit Theorem</strong> and assume that <span class="math inline">\(\overline{X}\)</span> is normally distributed. All that needs to be done is <strong>standardize</strong> <span class="math inline">\(\overline{X}\)</span> to get the corresponding Z statistic and compare that with the critical <strong>Z-score</strong>.</p>
<p>To standardize, the formula for the Z-score from Unit 3 is used. Note that this time, the variable to be standardized is <span class="math inline">\(\overline{X}\)</span>, not <span class="math inline">\(X\)</span>, and hence the appropriate mean and standard deviation must be used. We know that <span class="math inline">\(\overline{X} \sim N(\mu, SE = \sigma/\sqrt{n})\)</span> and so:</p>
<p><span class="math display">\[
\begin{align}
Z &amp;= \frac{\overline{X} - \mu}{SE} \\
&amp;= \frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \\
&amp;= \frac{\sqrt{n} \cdot \big(\overline{X} - \mu\big)}{\sigma}
\end{align}
\]</span></p>
<p>To find the critical Z-score corresponding to <span class="math inline">\(\alpha/2\)</span>, one would need to look at the <strong>cumulative distribution function</strong> or CDF of the Z distribution. In general, the CDF gives the probability that a random variable is <strong>less than or equal</strong> to a certain value. Formally, the critical Z-score is computed as</p>
<p><span class="math display">\[c = \Phi^{-1}(1-\alpha_0/2) \cdot \frac{\sigma}{\sqrt{n}}\]</span></p>
<p>where <span class="math inline">\(\Phi\)</span> is the CDF of the standard normal distribution. Thankfully, because the standard normal distribution is commonly used, Z tables and computers have made this much easier. For the pasta problem, the Z-score for a two-tailed test corresponding to <span class="math inline">\(\alpha = 0.05\)</span> is 1.96. Therefore, we reject the null hypothesis if the calculated Z statistic, <span class="math inline">\(Z\)</span>, is <span class="math inline">\(&lt; -1.96\)</span> or <span class="math inline">\(&gt; 1.96\)</span>, which corresponds to the shaded regions below:</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="p-values" class="section level3">
<h3><span class="header-section-number">5.2.2</span> p-values</h3>
<p>P-values can also be used to decide whether or not the null hypothesis should be rejected. This can be done by using the standard normal distribution to get the cumulative probability, <span class="math inline">\(\Phi(Z)\)</span>, which corresponds to the <span class="math inline">\(Z\)</span> statistic we have computed from <span class="math inline">\(\overline{X}\)</span>. We reject the null hypothesis if <span class="math inline">\(\alpha \leq 1-\Phi(Z)\)</span>.</p>
</div>
</div>
<div id="students-t-distribution" class="section level2">
<h2><span class="header-section-number">5.3</span> Student’s t-distribution</h2>
<p>The Z-test assumes that the true variance of the population is known, which is not always the case. This renders the Z-test unusable. For these situations where the variance is unknown, we use the t-test, which is based on the t-distribution.</p>
<p>The t-distribution, originally called Student’s t-distribution (from the pseudonym “Student” of the inventor, William Sealy Gosset), has an extra parameter that describes the shape of the distribution. This parameter is called <strong>degrees of freedom</strong>, <span class="math inline">\(\nu\)</span>. The graph below shows how different values of <span class="math inline">\(\nu\)</span> affects the shape of the distribution.</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-24-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br></p>
</div>
<div id="a-simple-t-test-example" class="section level2">
<h2><span class="header-section-number">5.4</span> A Simple t-test Example</h2>
<p>Just like the z-test, we can also test if the mean of a sample is significantly different from the population mean. For example, for a two-tailed setup like:</p>
<p><span class="math display">\[
\begin{aligned}
  H_0 &amp;: \mu = \mu_0 \\
  H_1 &amp;: \mu \neq \mu_0
\end{aligned}
\]</span></p>
<p>We can then calculate for the variable <span class="math inline">\(U\)</span>:</p>
<p><span class="math display">\[U=\sqrt{n} \cdot \frac{|\overline{X} - \mu_0|}{\hat{\sigma}}\]</span></p>
<p>Notice that there is now a new variable, <span class="math inline">\(\hat{\sigma}\)</span>. This represents the sample standard deviation. In previous sections, the sample standard deviation was represented as <span class="math inline">\(s\)</span>, and these two notations can be used interchangeably. In general, the caret (<span class="math inline">\(\hat{}\)</span>) is used to denote an estimate of a population parameter, which in this context is usually the sample statistic.</p>
<p>The sample standard deviation <span class="math inline">\(\hat{\sigma}\)</span> can be calculated as:</p>
<p><span class="math display">\[\hat{\sigma}=\sqrt{\frac{\sum_i^n{(X_i -\overline{X})^2}}{n-1}}\]</span></p>
<p>Like the Z-test, we reject <span class="math inline">\(H_0\)</span> if the statistic <span class="math inline">\(U\)</span> is greater than or equal to a critical statistic <span class="math inline">\(c\)</span>, i.e. when <span class="math inline">\(U \geq c\)</span> given that <span class="math inline">\(\mu = \mu_0\)</span>. The critical statistic <span class="math inline">\(c\)</span> is computed by <span class="math inline">\(T^{-1}_{n-1}(1-\alpha/2)\)</span> (for a two-tailed test) where <span class="math inline">\(T_{n-1}\)</span> is the cumulative density function of the <span class="math inline">\(t\)</span>-distribution for <span class="math inline">\(n-1\)</span> degrees of freedom. Below is the <span class="math inline">\(t\)</span>-distribution with 5 degrees of freedom:</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-25-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br></p>
</div>
<div id="tests-for-composite-hypotheses" class="section level2">
<h2><span class="header-section-number">5.5</span> Tests for Composite Hypotheses</h2>
<div id="rejection-regions" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Rejection Regions</h3>
<p>In obtaining the <span class="math inline">\(Z\)</span>- or <span class="math inline">\(t\)</span>-statistic for a composite hypothesis setup, the following formula is used:</p>
<p><span class="math display">\[Z = \sqrt{n} \cdot \frac{(\overline{X} - \mu_0)}{\sigma}, \hspace{10mm} U = \sqrt{n} \cdot \frac{(\overline{X} - \mu_0)}{S_X}\]</span></p>
<p>Comparing this with the equation for a simple hypothesis setup, notice that the only change here is the absence of the absolute value symbol. Because this is a one-tailed test, we now care about the direction of statistic. For a <strong>left-tailed</strong> test, we reject <span class="math inline">\(H_0\)</span> if the test statistic <span class="math inline">\(U \leq c\)</span>, while for a <strong>right-tailed</strong> test, we reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(U \geq c\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-26"></span>
<img src="intro-statistics_files/figure-html/unnamed-chunk-26-1.png" alt="Rejection Region for a Left-tailed Test" width="672" />
<p class="caption">
Figure 5.1: Rejection Region for a Left-tailed Test
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-27"></span>
<img src="intro-statistics_files/figure-html/unnamed-chunk-27-1.png" alt="Rejection Region for a Right-tailed Test" width="672" />
<p class="caption">
Figure 5.2: Rejection Region for a Right-tailed Test
</p>
</div>
</div>
<div id="calculating-p-values" class="section level3">
<h3><span class="header-section-number">5.5.2</span> Calculating p-values</h3>
<p>For the one-tailed test, we calculate the p-values based on the alternative hypothesis. For example, if we have <span class="math inline">\(H_1:\mu &lt; \mu_0\)</span>, then we are to find:</p>
<p><span class="math display">\[
\begin{aligned}
\phi(Z) \quad &amp;\text{(for z-test)} \\
T_{n-1}(U)\quad &amp;\text{(for t-test)}
\end{aligned}
\]</span></p>
<p>On the other hand, for <span class="math inline">\(H_1: \mu &gt; \mu_0\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
1-\phi(Z) \quad &amp;\text{(for z-test)} \\
1-T_{n-1}(U)\quad &amp;\text{(for t-test)}
\end{aligned}
\]</span></p>
<p>Note that <span class="math inline">\(\Phi\)</span> and <span class="math inline">\(T\)</span> are the <strong>cumulative distribution functions</strong> or CDFs, and they always give the areas of the left tail. Visualizing the rejection regions will explain why we subract the area from 1 in a right-tailed test.</p>
<p><br></p>
</div>
</div>
<div id="a-two-sample-t-test" class="section level2">
<h2><span class="header-section-number">5.6</span> A Two-Sample t-test</h2>
<p>There are situations when we want to compare two groups and test if their population means are different, or if one is greater than (or less than) relative to the other. In other words, instead of comparing <span class="math inline">\(\mu\)</span> to a reference value <span class="math inline">\(\mu_0\)</span>, we are now comparing two population means - <span class="math inline">\(\mu_X\)</span> and <span class="math inline">\(\mu_Y\)</span>.</p>
<p>For a two-sampled test, we now have a new way of calculating the t-statistic. incorporating the new variables <span class="math inline">\(\overline{Y}\)</span> and <span class="math inline">\(\hat{\sigma_Y}\)</span>. Below is the formal definition of a two-sample t-statistic:</p>
<p><span class="math display">\[
\begin{aligned}
U = \frac{(m+n-2)^{1/2}(\overline{X} - \overline{Y})}{(\frac{1}{m} + \frac{1}{n})^{1/2}(S^2_X+S^2_Y)^{1/2}}
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\overline{X}\)</span> and <span class="math inline">\(\overline{Y}\)</span> are the respective sample means and <span class="math inline">\(S_X^2\)</span> and <span class="math inline">\(S_Y^2\)</span> are the residual sum of squares or RSS, defined as <span class="math inline">\(S_X^2 = \sum_i^m(X_i - \overline{X})^2\)</span> and <span class="math inline">\(S^2_Y = \sum_j^n(Y_j - \overline{Y})^2\)</span>. We use the t-distribution with <span class="math inline">\(m + n - 2\)</span> degrees of freedom for inference in this case.</p>
</div>
<div id="hypothesis-testing-examples" class="section level2">
<h2><span class="header-section-number">5.7</span> Hypothesis Testing Examples</h2>
<div id="problem-1" class="section level3">
<h3><span class="header-section-number">5.7.1</span> Problem 1</h3>
<div class="prob">
<p>The manufacturer of a certain automobile claims that under typical urban driving conditions, the automobile will travel on average at least 20 miles per gallon of gasoline. An owner of one of these automobile notes the mileages that she has obtained in her own urban driving when she fills her automobile’s tank with gasoline on nine different occasions. Her records show the following, in miles per gallon: 15.6, 18.6, 18.3, 20.1, 21.5, 18.4, 19.1, 20.4, and 19.0. Test the manufacturer’s claim by carrying out a test at a significance level <span class="math inline">\(\alpha\)</span> = 0.05.</p>
</div>
<p><br></p>
<p>To solve this problem, we first need to formulate the hypothesis that is being asked. Since the manufacturer claims that the car runs on <strong>“at least”</strong> 20 miles per gallon, we can say that the null and alternative hypotheses are:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \mu \geq 20 \\
H_1 &amp;: \mu &lt; 20
\end{aligned}
\]</span></p>
<p>We do not have information about the population variance and thus we use a <strong>t-test</strong>. The next step would be to calculate the t-statistic. The sample mean in this case is simply:</p>
<p><span class="math display">\[
\begin{aligned}
\overline{X} &amp;= \frac{\sum^{n}_{i}X_{i}}{n}\\
&amp;= \frac{(15.6 + 18.6 + 18.3 + 20.1 + 21.5 + 18.4 + 19.1 + 20.4 + 19.0)}{9} \\
&amp;= 19
\end{aligned}
\]</span></p>
<p>The sample standard deviation is calculated as:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\sigma} &amp;= \frac{\sum_{i}^{n}(X_i - \overline{X})^2}{n-1}\\
&amp;= \frac{\sum_{i}^{n}(X_i-19)^2}{n-1} \\
&amp;= 1.66 
\end{aligned}
\]</span></p>
<p>Putting this all together, we calculate the t-statistic to be:</p>
<p><span class="math display">\[
\begin{aligned}
U &amp;= \frac{\sqrt{n} \cdot (\overline{X} - \mu_0)}{S_X} \\
&amp;= \frac{\sqrt{9} \cdot (19 - 20)}{1.66} \\
&amp;= -1.81
\end{aligned}
\]</span></p>
<p>We can decide whether or not to reject the null hypothesis by either calculating the critical statistic or the p-value.</p>
<div id="critical-statistic" class="section level4">
<h4><span class="header-section-number">5.7.1.1</span> Critical Statistic</h4>
<p>The critical statistic is the t-statistic that corresponds to <span class="math inline">\(1 - \alpha\)</span>, that is, getting the value of <span class="math inline">\(T^{-1}_{n-1}(1-\alpha)\)</span> where <span class="math inline">\(T^{-1}_{n-1}\)</span> is the inverse of the CDF with <span class="math inline">\(n-1\)</span> degrees of freedom. The degrees of freedom here is <span class="math inline">\(\nu = n-1 = 8\)</span>.</p>
<p>In <strong>Microsoft Excel</strong> this can be done using the function <code>T.INV</code> with arguments <code>probability</code> and <code>deg_freedom</code>. For probability <span class="math inline">\(alpha_0 = 0.05\)</span>, and 8 degrees of freedom, we get <span class="math inline">\(c = -1.86\)</span>. Since <span class="math inline">\(U = -1.81 &gt; -1.86\)</span>, we do not reject the null hypothesis and conclude that the evidence gathered by the owner supports the manufacturer’s claim that the automobile runs at 20 mpg on average.</p>
</div>
<div id="calculating-the-p-value" class="section level4">
<h4><span class="header-section-number">5.7.1.2</span> Calculating the p-value</h4>
<p>We get the p-value by using the CDF of the t-distribution <span class="math inline">\(T_{n-1}(U)\)</span>. This can achieved in <strong>Microsoft Excel</strong> by calling the function <code>T.DIST</code> with arguments <code>X</code>, which is the statistic for which we evaluate the CDF (which is <span class="math inline">\(U\)</span> in this case), <code>deg_freedom</code>, and <code>cumulative</code> which tells the function if we want to add up the densities of the distribution. Since the function is by default left-tailed, the densities are added up from left to right. This is shown below:</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-30-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Since we want to test if there is enough evidence to reject <span class="math inline">\(\mu \geq 20\)</span>, it makes sense to get the cumulative probability from the left. It would mean that highly negative values for the statistic are highly unlikely since going from left to right correspond to increasing probabilities.</p>
<p>For this problem, we calculate <span class="math inline">\(p = 1 - T_{n-1}(U) = 0.054\)</span>. Since <span class="math inline">\(p &gt; \alpha_0\)</span> we do not reject the null hypothesis at <span class="math inline">\(\alpha_0 = 0.05\)</span>.</p>
<p><br></p>
</div>
</div>
<div id="problem-2" class="section level3">
<h3><span class="header-section-number">5.7.2</span> Problem 2</h3>
<div class="prob">
<p>As a marketing executive, you are curious if a social media marketing strategy would be more effective than the current paid media marketing strategy of the retail company. To investigate this, you ran two different marketing campaigns alternately for a total of 12 months. The number of sales was recorded each month as shown below:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
months
</th>
<th style="text-align:left;">
Marketing Strategies
</th>
<th style="text-align:right;">
Sales
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
January
</td>
<td style="text-align:left;">
social media
</td>
<td style="text-align:right;">
26
</td>
</tr>
<tr>
<td style="text-align:left;">
February
</td>
<td style="text-align:left;">
paid media
</td>
<td style="text-align:right;">
77
</td>
</tr>
<tr>
<td style="text-align:left;">
March
</td>
<td style="text-align:left;">
social media
</td>
<td style="text-align:right;">
16
</td>
</tr>
<tr>
<td style="text-align:left;">
April
</td>
<td style="text-align:left;">
paid media
</td>
<td style="text-align:right;">
84
</td>
</tr>
<tr>
<td style="text-align:left;">
May
</td>
<td style="text-align:left;">
social media
</td>
<td style="text-align:right;">
79
</td>
</tr>
<tr>
<td style="text-align:left;">
June
</td>
<td style="text-align:left;">
paid media
</td>
<td style="text-align:right;">
96
</td>
</tr>
<tr>
<td style="text-align:left;">
July
</td>
<td style="text-align:left;">
social media
</td>
<td style="text-align:right;">
82
</td>
</tr>
<tr>
<td style="text-align:left;">
August
</td>
<td style="text-align:left;">
paid media
</td>
<td style="text-align:right;">
14
</td>
</tr>
<tr>
<td style="text-align:left;">
September
</td>
<td style="text-align:left;">
social media
</td>
<td style="text-align:right;">
50
</td>
</tr>
<tr>
<td style="text-align:left;">
October
</td>
<td style="text-align:left;">
paid media
</td>
<td style="text-align:right;">
82
</td>
</tr>
<tr>
<td style="text-align:left;">
November
</td>
<td style="text-align:left;">
social media
</td>
<td style="text-align:right;">
35
</td>
</tr>
<tr>
<td style="text-align:left;">
December
</td>
<td style="text-align:left;">
paid media
</td>
<td style="text-align:right;">
36
</td>
</tr>
</tbody>
</table>
Apply hypothesis testing to find out whether there is evidence that social media marketing is better than paid media marketing in generating sales.<br />

</div>
<p><br></p>
<p>We want to find out if social media marketing (S) is better than paid media marketing (P). The hypotheses can be set up as follows:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \mu_{S} \leq \mu_{P} \\
H_1 &amp;: \mu_{S} &gt; \mu_{P}
\end{aligned}
\]</span></p>
<p>With these statements, the null hypothesis states that social media marketing is at most as good as paid marketing, while <span class="math inline">\(H_1\)</span> states that social media marketing generates more sales.</p>
<p>This problem compares two samples, sales due to social media marketing and sales due to paid media marketing. Hence, we use the <span class="math inline">\(t\)</span>-statistic definition for two samples.</p>
<p>Below are the sample means and standard deviations for both <em>paid media</em> and <em>social media</em>:</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Marketing Strategies
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
Standard Deviation
</th>
<th style="text-align:right;">
Sum of Squares (S)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
social media
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
27.6
</td>
<td style="text-align:right;">
3798.0
</td>
</tr>
<tr>
<td style="text-align:left;">
paid media
</td>
<td style="text-align:right;">
64.8
</td>
<td style="text-align:right;">
32.2
</td>
<td style="text-align:right;">
5196.8
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>Using this information, we then calculate the <span class="math inline">\(t\)</span>-statistic. Since both marketing strategies were both deployed for an equal number of months during the year, we can say that <span class="math inline">\(m = n = 6\)</span>.</p>
<p>$$
\begin{aligned}
U &amp;= 
{( + )(S<sup>2_X+S</sup>2_Y)^{1/2}} \</p>
<p>&amp;= 
{( + )(3,798 + 5,196.8)^{1/2}} \</p>
<p>&amp;= -0.971
\end{aligned}
$$</p>
<p>Since we are testing for <span class="math inline">\(H_0: \mu_{SM} \leq \mu_{PM}\)</span>, we reject it if the statistic <span class="math inline">\(U \geq c\)</span>, where <span class="math inline">\(c\)</span> is equal to <span class="math inline">\(T^{-1}_{m+n-1}(1-\alpha_0)\)</span>. For <span class="math inline">\(\text{df} = m + n - 2 = 10\)</span>, the <span class="math inline">\(t\)</span>-statistic at <span class="math inline">\(1 - \alpha\)</span> is equal to 1.81. Since <span class="math inline">\(U &lt; c\)</span> we do not reject the null hypothesis.</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-35-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>To obtain the p-value, we get the cumulative probability from the cdf <span class="math inline">\(T_{m+n-2}(U)\)</span>. Looking at <span class="math inline">\(H_0\)</span>, we reject positive values and thus it would make sense to get the area of the right-tail, <span class="math inline">\(1 - T_{m+n-2}(U)\)</span>, where a lower probability would mean a very unlikely outcome given the null hypothesis. We get this using the Excel formula <code>= 1 - T.DIST(-0.971, 10, TRUE)</code>.</p>
<p>We calculate the p-value as <span class="math inline">\(0.82\)</span>. At significance level <span class="math inline">\(\alpha = 0.05\)</span>, we do
not reject the null hypothesis. We visualize this below:</p>
<p><img src="intro-statistics_files/figure-html/unnamed-chunk-36-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br></p>
</div>
</div>
<div id="confidence-intervals" class="section level2">
<h2><span class="header-section-number">5.8</span> Confidence Intervals</h2>
<div id="what-are-confidence-intervals" class="section level3">
<h3><span class="header-section-number">5.8.1</span> What are confidence intervals?</h3>
<p>Confidence intervals give us a range of plausible values for the population parameter based on results from a sample. The conditions for the CLT must also be met for the confidence interval to be valid.</p>
</div>
<div id="constructing-a-confidence-interval" class="section level3">
<h3><span class="header-section-number">5.8.2</span> Constructing a Confidence Interval</h3>
<p>The confidence interval <strong>for the mean</strong> is computed as:</p>
<p><span class="math display">\[\bigg(\overline{X} - c \cdot \frac{s}{\sqrt{n}}, ~ \overline{X} + c \cdot \frac{s}{\sqrt{n}}\bigg)\]</span></p>
<ul>
<li><span class="math inline">\(\overline{x}\)</span> is the sample mean<br />
</li>
<li><span class="math inline">\(s\)</span> is the sample standard deviation<br />
</li>
<li><span class="math inline">\(n\)</span> is the sample size<br />
</li>
<li><span class="math inline">\(c\)</span> is the critical statistic</li>
</ul>
<p>The quantity <span class="math inline">\(c \cdot \frac{s}{\sqrt{n}}\)</span> is called the <strong>margin of error</strong>.</p>
<p>The critical statistic can either be a Z-score (<span class="math inline">\(Z\)</span>) or t-score (<span class="math inline">\(U\)</span>), depending on which distribution is used for inference. This statistic is related to the significance level <span class="math inline">\(\alpha\)</span> that was previously set. Recall from Unit 4 that <span class="math inline">\(\alpha\)</span> or the Type I error rate is the probability of rejecting a true <span class="math inline">\(H_0\)</span>. Increasing <span class="math inline">\(\alpha\)</span> means increasing the tolerance for making a wrong decision, and so “confidence” in the analysis decreases. This is why the confidence level is computed as <span class="math inline">\(1 - \alpha\)</span>. For <span class="math inline">\(\alpha = 0.05\)</span>, the confidence level is <span class="math inline">\(1 - 0.05 = 0.95\)</span> or 95%. In computing a 95% CI, the <span class="math inline">\(Z\)</span>-score corresponding to the confidence level is used. For example, if <span class="math inline">\(\alpha = 0.05\)</span> and the <span class="math inline">\(Z\)</span>-distribution is used, the critical Z-score which we will denote as <span class="math inline">\(z^*\)</span> is the <span class="math inline">\(Z\)</span>-score corresponding to 0.95.</p>
</div>
<div id="interpreting-the-confidence-interval" class="section level3">
<h3><span class="header-section-number">5.8.3</span> Interpreting the Confidence Interval</h3>
<p>As an example, consider the mileage problem from the previous section. The sample mean <span class="math inline">\(\overline{X}\)</span> was 19 while the sample standard deviation was 1.6583124. The population variance is unknown, so the t-test was used. The critical <span class="math inline">\(t\)</span>-score corresponding to <span class="math inline">\(1 - \alpha = 0.95\)</span> is 1.86, and the sample size is 9. Using these information, we can construct a 95% confidence interval for the true average MPG of the car:</p>
<p><span class="math display">\[
\begin{align}
&amp; \bigg(\overline{X} \pm c \cdot \frac{s}{\sqrt{n}} \bigg) \\
&amp;= \bigg(19 \pm -1.86 \times \frac{1.66}{\sqrt{9}} \bigg)\\
&amp;= (19 \pm -1.86 \times 0.5533 ) \\
&amp;= (19 \pm 1.03) \\
&amp;= (17.97, ~ 20.03)
\end{align}
\]</span></p>
<p>This 95% confidence interval <strong>IS NOT</strong> interpreted as: “There is a 95% chance that the true mean is in this interval.” The correct interpretation of a confidence interval is: “95% of <em>similarly constructed</em> intervals will contain the true population mean.”</p>
<p><br></p>

</div>
</div>
</div>


























            </section>

          </div>
        </div>
      </div>
<a href="hypothesis-testing.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
